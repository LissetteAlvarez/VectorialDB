{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1r0iCZjmH2VmViLB39z8Wgde5M_z3d1ee",
      "authorship_tag": "ABX9TyPH9tYtpk8m25eWRQKrq3ty",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LissetteAlvarez/VectorialDB/blob/main/pineconedemo_vectordatabases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pinecone demo básica (simple pinecone demo)"
      ],
      "metadata": {
        "id": "pk-841IdWw_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La librería pinecone-client nos permitirá acceder al servicio de la base de datos Pinecone.\n",
        "\n",
        "Utilizaremos la librería sentence-transformer para generar los embeddings de texto que añadiremos a la base de datos.\n",
        "\n",
        "Instalemos las librerias:\n"
      ],
      "metadata": {
        "id": "gqvHc7QFYxn1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzq6i6-7Jiwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8688c325-7ccd-461e-b549-a7b34bed930a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (3.2.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.2.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.11.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pinecone-client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers"
      ],
      "metadata": {
        "id": "Fc0Oa_UeU4ix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1563b518-ba3e-4674-e89e-f8ff2d6b5371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Generando embeddings\n",
        "En primer lugar codificaremos un conjunto de datos de texto (**embeddings**) para almacenarlos en la base de datos vectorial. Para ello, utilizaremos la biblioteca SentenceTransformers.\n",
        "\n",
        "Esta biblioteca proporciona arquitecturas basadas en **`Transformers`** pre-entrenados que pueden codificar texto de forma eficiente en representaciones vectoriales densas (embeddings). Los embeddings capturan similitudes semánticas y relaciones entre textos, lo que las hace adecuadas para tareas posteriores de clasificación y agrupación.\n",
        "\n",
        "**`SentenceTransformers`** ofrece varias arquitecturas pre-entrenadas como BERT, RoBERTa y DistilBERT. En esta demo utilizaremos DistilBERT, ya que  es un modelo relativamente ligero."
      ],
      "metadata": {
        "id": "6prbaZuiVPrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone, PodSpec\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "03Q1vdtvU-xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos una instancia de DistilBERT:"
      ],
      "metadata": {
        "id": "HCy9tWo6VkhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo\n",
        "model_name = 'distilbert-base-nli-stsb-mean-tokens'\n",
        "model = SentenceTransformer(model_name)"
      ],
      "metadata": {
        "id": "5zyPJ1WAVDQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94bdbe6-d245-4307-ece8-3eabf66f88a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para acceder al servicio de Pinecone, necesitamos una API key.\n",
        "Puedes encontrarla accediendo a tu cuenta Pinecone y accediendo a la sección:  \n",
        "`API Keys -> Create API Key -> Enter API Key Name -> Create`.\n",
        "\n",
        "Si aún no posees cuenta en Pinecone, puedes crearla aquí:\n",
        "https://app.pinecone.io/?sessionType=signup.\n",
        "\n",
        "\n",
        "Hay dos formas de añadir la API Key si estás codificando en Google Colab: añadiendo directamente la contraseña al código o gestionando las variables de entorno almacenadas en 'Secretos'.\n",
        "\n",
        "Veamos ambos métodos.\n",
        "\n"
      ],
      "metadata": {
        "id": "ECUDjnMmVlUY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conectar Pinecone desde el código\n",
        "Añade la API key al código:"
      ],
      "metadata": {
        "id": "Gj9GAQVqg5gI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pinecone connect\n",
        "# pinecone_key = \"<Add touy Pinecone API key here>\"\n",
        "# pc_service = Pinecone(api_key = pinecone_key)"
      ],
      "metadata": {
        "id": "HwVoFFCjVqhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gestionando las variables de entorno de Google Colab:\n",
        "\n",
        "Para la API key desde el servicio de gestión de variables de entorno de Google Colab (**Secrets**), recuperamos la API key con `userdata.get()`. En mi caso, la he almacenado con el nombre 'Pinecone_key'.\n",
        "\n",
        "Es importante dar acceso al cuaderno a la variable de entorno correspondiente, activando el botón 'Acces desde el cuaderno' de la sección '**Secretos**' disponible en el panel lateral izquierdo:\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1g4FDpxdPqQbQZIovOkubLtRBshwli0Ji)\n",
        "\n"
      ],
      "metadata": {
        "id": "i0nRhR3KSNVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "pinecone_key = userdata.get('Pinecone_key')\n",
        "os.environ['pinecone_key'] = pinecone_key\n",
        "pc_service = Pinecone(api_key = pinecone_key)"
      ],
      "metadata": {
        "id": "kfnlmDCSWWbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generando índices y embeddings\n",
        "\n",
        "En Pinecone, los embeddings se almacenan en índices. Todos los embeddigns deben calcularse con la misma distancia y tener la misma dimensionalidad para medir adecuadamente la similitud entre ellos.\n",
        "\n",
        "En primer lugar utilizamos el `método list_indexes()` para crear una lista vacía de índices. Luego, creamos los índices utilizando el método `create_index()`.\n",
        "\n"
      ],
      "metadata": {
        "id": "hMdzvwQkV92h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Lista vacía de índices\n",
        " pc_service.list_indexes()"
      ],
      "metadata": {
        "id": "EHTZaPNXV4Ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73fad245-958e-454c-a125-bdd8db9eac0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'indexes': []}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear índices\n",
        "pc_service.create_index(\n",
        "    name=\"vector-demo\",\n",
        "    dimension=768,\n",
        "    metric=\"euclidean\",\n",
        "    spec=PodSpec(environment=\"gcp-starter\")\n",
        "  )"
      ],
      "metadata": {
        "id": "U9v31I_WWUJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los argumentos de la función `create_index()` son:\n",
        "\n",
        "**`name`**: nombre del índice (definido por el usuario). Puede utilizarse para referirse al índice más adelante cuando se realicen operaciones sobre él.\n",
        "\n",
        "**`dimension`**: define la dimensionalidad de los vectores que se almacenarán en el índice. Debe coincidir con la dimensionalidad de los vectores que se insertarán en el índice. En este caso, el valor 768 corresponde a la dimensión de embedding devuelta por el modelo `SentenceTransformer`.\n",
        "\n",
        "**`metric`**: métrica de distancia utilizada para calcular la similitud entre vectores.\n",
        "\n",
        "**`spec`**: Un objeto PodSpec que especifica el entorno en el que se creará el índice. En este ejemplo, el índice se crea en un entorno GCP (Google Cloud Platform) llamado `gcp-starter`."
      ],
      "metadata": {
        "id": "JybcLsunWsKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez creados los índices, agregamos los vectores de embeddings.\n",
        "\n",
        "Para ello, creamos un dataset de texto como ejemplo y lo codificamos utilizando el modelo `SentenceTransformer` model:"
      ],
      "metadata": {
        "id": "5IcCGDr7Xdc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset de ejemplo\n",
        "data = [\n",
        "    {\"id\": \"vector1\",  \"text\": \"I love using vector databases\"},\n",
        "    {\"id\": \"vector2\",  \"text\": \"Vector databases are great for storing and retrieving vectors\"},\n",
        "    {\"id\": \"vector3\",  \"text\": \"Using vector databases makes my life easier\"},\n",
        "    {\"id\": \"vector4\",  \"text\": \"Vector databases are efficient for storing vectors\"},\n",
        "    {\"id\": \"vector5\",  \"text\": \"I enjoy working with vector databases\"},\n",
        "    {\"id\": \"vector6\",  \"text\": \"Vector databases are useful for many applications\"},\n",
        "    {\"id\": \"vector7\",  \"text\": \"I find vector databases very helpful\"},\n",
        "    {\"id\": \"vector8\",  \"text\": \"Vector databases can handle large amounts of data\"},\n",
        "    {\"id\": \"vector9\",  \"text\": \"I think vector databases are the future of data storage\"},\n",
        "    {\"id\": \"vector10\", \"text\": \"Using vector databases has improved my workflow\"}\n",
        "]"
      ],
      "metadata": {
        "id": "m3FaAvKrWr1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embeddings\n",
        "vector_data = []\n",
        "\n",
        "for sentence in data:\n",
        "\n",
        "    embedding = model.encode(sentence[\"text\"])\n",
        "    vector_info = {\"id\":sentence[\"id\"], \"values\": embedding.tolist()}\n",
        "\n",
        "    vector_data.append(vector_info)"
      ],
      "metadata": {
        "id": "Z__HptlOXvJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este fragmento de código codifica el texto de cada frase en un vector utilizando el modelo `sentence transformer`.\n",
        "\n",
        "A continuación, crea un diccionario (`vector_info`) que contiene el ID de la frase (`id`) y el vector correspondiente (`values`), y añade este diccionario a la lista `vector_data`.\n",
        "\n",
        "Cuando existen múltiples índices bajo la misma cuenta, debemos crear un objeto índice que indique a cuál índice deseamos añadir los embeddings:"
      ],
      "metadata": {
        "id": "yIW4g51-X2Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Especificar índice para los embeddings\n",
        "index = pc_service.Index(\"vector-demo\")"
      ],
      "metadata": {
        "id": "To5YcRrZX6Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insertando los embeddings a la DB\n",
        "\n",
        "Una vez generados los embeddings y el índice donde deseamos agregarlos, podemos insertar los embeddings. Este proceso, conocido como 'upsert', combina las acciones de actualización e inserción:\n",
        "\n",
        "*   Inserta un nuevo documento en una colección si el documento aún no existe, o\n",
        "*   Actualiza un documento existente si ya existe.\n"
      ],
      "metadata": {
        "id": "00MqHdxlX-Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upsert embeddings to index\n",
        "index = pc_service.Index(\"vector-demo\")\n",
        "\n",
        "index.upsert(vectors=vector_data)"
      ],
      "metadata": {
        "id": "r7jNVi15YCCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf09a89-e2f4-44e4-91b5-86e29afeebd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'upserted_count': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listo! El proceso a añadido (o actualzado) 10 registros.\n",
        "\n",
        "Ppodemos utilizar `describe_index_stats` para comprobar que la cantidad de vectores actuales coincide con el número de vectores que hemos añadido:"
      ],
      "metadata": {
        "id": "htwsqrWKYLjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobación\n",
        "index.describe_index_stats()\n"
      ],
      "metadata": {
        "id": "MQoVwvY6YL7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed3ca62-6f12-48ad-d289-f892514cf283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 768,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La salida nos ofrece la siguiente información:\n",
        "\n",
        "\n",
        "* **`dimensión`**: La dimensionalidad de los vectores almacenados en el índice (768, en este caso)\n",
        "*   **`index_fullness`**: indica el porcentaje de espacios en el índice que están ocupados\n",
        "*   **`namespaces`**: diccionario que contiene estadísticas para cada namespaces en el índice. En este caso, solo hay un namespace (`''`) con un `vector_count` de 10, lo que indica que hay 10 vectores en el índice.\n",
        "*   **`total_vector_count`**: número total de vectores en el índice en todos los namespaces (10, en este caso).\n",
        "\n"
      ],
      "metadata": {
        "id": "LcAdsvlNYY6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Búsqueda en Pinecone\n",
        "Ahora que tenemos una base de datos en Pinecone, ejecutemos una búsqueda de con base en la similitud de los vectores.\n",
        "\n",
        "Primero, definimos un texto de búsqueda, esto es, un nuevo texto que tendremos que codificar para luego buscar el o los vectores con mayor similitud dentro de la base de datos.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cw1oR3pC4AoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto de búsqueda\n",
        "search_text = \"Vector database are really helpful\"\n",
        "\n",
        "# embedding\n",
        "search_embedding = model.encode(search_text).tolist()"
      ],
      "metadata": {
        "id": "akJ-XccmYhAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos el método `query()` para identificar los 3 'vecinos más cercanos':"
      ],
      "metadata": {
        "id": "g2EAHg4kYoDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectores más cercanos neighbors\n",
        "index.query(vector=search_embedding, top_k=3)"
      ],
      "metadata": {
        "id": "7HJkbU6EYqKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da76585d-9125-4a73-a073-591c0dc6fbdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'matches': [], 'namespace': '', 'usage': {'read_units': 5}}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iq = index.query(vector=search_embedding, top_k=3, include_metadata=True)\n",
        "for resultado in iq['matches']:\n",
        "    print(resultado['id'] )"
      ],
      "metadata": {
        "id": "0bWAmhoi627r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# closest neighbors\n",
        "print(data[7]['text'])\n",
        "print(data[4]['text'])\n",
        "print(data[5]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNDxhZSE8eF9",
        "outputId": "2907e260-5523-4ce2-8fda-2c16f6282eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector databases can handle large amounts of data\n",
            "I enjoy working with vector databases\n",
            "Vector databases are useful for many applications\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eliminamos el índice en Pinecone\n"
      ],
      "metadata": {
        "id": "JrPCg_MPY5Mr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pc_service.delete_index(\"vector-demo\")"
      ],
      "metadata": {
        "id": "yQwRjjkvDoNN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}